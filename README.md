# Gesture + Gaze Controlled 3D Interaction (Web)

A web-based 3D interaction demo that combines hand tracking and gaze estimation to create an immersive, futuristic user experience. Control 3D objects using hand gestures and head direction.

## ğŸ¯ Features

- **Hand Tracking**: Real-time hand landmark detection using MediaPipe
- **Pinch Gesture**: Detect and track pinch gestures for grabbing objects
- **Gaze Estimation**: Approximate head direction tracking for object selection
- **3D Interaction**: Smooth, physics-like object manipulation in a 3D scene
- **Visual Polish**: Glow effects, smooth animations, and modern UI

## ğŸ› ï¸ Tech Stack

- **Next.js 14** (App Router)
- **React Three Fiber** - React renderer for Three.js
- **Three.js** - 3D graphics library
- **MediaPipe** - Hand tracking
- **TensorFlow.js** - Face/head direction estimation
- **TypeScript** - Type safety

## ğŸ“ Project Structure

```
gesture-gaze-3d/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ page.tsx          # Main page component
â”‚   â”œâ”€â”€ layout.tsx        # Root layout
â”‚   â””â”€â”€ globals.css       # Global styles
â”‚
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ Scene/
â”‚   â”‚   â”œâ”€â”€ CanvasScene.tsx      # Main 3D canvas
â”‚   â”‚   â”œâ”€â”€ InteractiveObject.tsx # 3D interactive objects
â”‚   â”‚   â””â”€â”€ Lighting.tsx         # Scene lighting setup
â”‚   â”‚
â”‚   â”œâ”€â”€ Vision/
â”‚   â”‚   â”œâ”€â”€ useWebcam.ts         # Webcam access hook
â”‚   â”‚   â”œâ”€â”€ useHandTracking.ts   # MediaPipe hand tracking
â”‚   â”‚   â”œâ”€â”€ useFaceTracking.ts   # Head direction estimation
â”‚   â”‚   â””â”€â”€ VisionProvider.tsx   # Vision context provider
â”‚   â”‚
â”‚   â”œâ”€â”€ Interaction/
â”‚   â”‚   â”œâ”€â”€ usePinchGesture.ts   # Pinch detection logic
â”‚   â”‚   â”œâ”€â”€ useGrabController.ts # Grab state machine
â”‚   â”‚   â”œâ”€â”€ GazeRayProvider.tsx  # Gaze ray calculation
â”‚   â”‚   â”œâ”€â”€ InteractionProvider.tsx # Interaction context
â”‚   â”‚   â””â”€â”€ InteractionContext.tsx   # Object registry
â”‚   â”‚
â”‚   â””â”€â”€ UI/
â”‚       â”œâ”€â”€ DebugPanel.tsx       # Debug information overlay
â”‚       â””â”€â”€ Overlay.tsx          # Loading/error overlay
â”‚
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ math/
â”‚   â”‚   â”œâ”€â”€ vectorUtils.ts       # Vector math utilities
â”‚   â”‚   â”œâ”€â”€ screenToWorld.ts     # Coordinate transformations
â”‚   â”‚   â””â”€â”€ smoothing.ts         # Smoothing algorithms
â”‚   â”‚
â”‚   â””â”€â”€ constants.ts            # Configuration constants
â”‚
â””â”€â”€ types/
    â”œâ”€â”€ hand.ts                 # Hand tracking types
    â”œâ”€â”€ gaze.ts                 # Gaze estimation types
    â””â”€â”€ interaction.ts          # Interaction state types
```

## ğŸš€ Getting Started

### Prerequisites

- Node.js 18+ 
- npm or yarn
- Webcam access

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd gesture-gaze-3d
```

2. Install dependencies:
```bash
npm install
```

3. Run the development server:
```bash
npm run dev
```

4. Open [http://localhost:3000](http://localhost:3000) in your browser

5. Allow camera access when prompted

## ğŸ® How to Use

1. **Allow Camera Access**: Grant permission for webcam access when prompted
2. **Look at Objects**: Move your head to aim your gaze at 3D objects - they will glow when hovered
3. **Pinch to Grab**: Make a pinch gesture (thumb and index finger together) while looking at an object to grab it
4. **Move Objects**: While pinching, move your hand to drag the object in 3D space
5. **Release**: Open your hand to release the object

### Debug Mode

Add `?debug=true` to the URL to enable the debug panel, which shows:
- FPS counter
- Hand detection status
- Gaze tracking status
- Pinch gesture state
- Real-time position data

## ğŸ§  Architecture Overview

### Vision Layer
- **useWebcam**: Manages webcam stream
- **useHandTracking**: MediaPipe hand landmark detection
- **useFaceTracking**: Simplified head pose estimation

### Gesture Layer
- **usePinchGesture**: Calculates pinch state from hand landmarks
- Distance threshold between thumb and index finger tips
- Temporal smoothing for stable detection

### Gaze Layer
- **GazeRayProvider**: Converts head direction to 3D ray
- Raycasting for object intersection detection

### Interaction Layer
- **useGrabController**: State machine (IDLE â†’ HOVER â†’ GRABBING â†’ RELEASE)
- Coordinate mapping from screen space to 3D world space
- Smooth object movement with lerp interpolation

### 3D Layer
- **CanvasScene**: React Three Fiber canvas setup
- **InteractiveObject**: 3D meshes with hover/glow effects
- **Lighting**: Ambient, directional, and point lights

## ğŸ“ Coordinate Mapping

The system maps hand positions from normalized screen coordinates (0-1) to 3D world space:

1. Normalized screen coordinates â†’ NDC (-1 to 1)
2. Raycast from camera through NDC point
3. Intersect with plane at fixed Z depth
4. Map intersection point to object position

## âš™ï¸ Configuration

Key constants in `lib/constants.ts`:

- `PINCH_DISTANCE_THRESHOLD`: Distance threshold for pinch detection
- `GRAB_SMOOTHING`: Lerp factor for smooth object movement
- `LERP_FACTOR`: Animation smoothing factor
- `GLOW_INTENSITY`: Hover glow effect intensity

## ğŸ¨ Visual Features

- **Dark Theme**: Futuristic dark background (#0a0a0a)
- **Glow Effects**: Objects emit colored glow on hover
- **Smooth Animations**: Lerp-based interpolation for fluid movement
- **Shadows**: Soft shadows for depth perception
- **Bloom**: Subtle emissive materials for modern look

## ğŸ› Known Limitations

- Face tracking is simplified (uses center-based estimation)
- Single hand tracking only
- Desktop browser only (no mobile support)
- Requires good lighting for reliable hand detection

## ğŸ”œ Phase B (Future Enhancements)

- MediaPipe Face Mesh integration for accurate head pose
- Kalman filter for smoother tracking
- Multi-object support with collision detection
- Performance profiling and optimization
- Raycast optimization
- Mathematical documentation

## ğŸ“ License

This project is a demo/portfolio piece. Feel free to use as inspiration for your own projects.

## ğŸ™ Credits

- MediaPipe for hand tracking
- Three.js and React Three Fiber communities
- TensorFlow.js team

---

**Note**: This is a Phase A demo focused on UX and visual polish. Phase B will include more robust tracking and performance optimizations.
